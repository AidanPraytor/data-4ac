{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rqGJpQTYpDaM"
   },
   "source": [
    "# Dissecting racial bias in a medical risk score algorithm\n",
    "\n",
    "ML Failures lab: Dissecting Racial Bias by Nick Merrill, Inderpal Kaur, Samuel Greenberg is licensed under CC BY-NC-SA 4.0. To view a copy of this license, visit https://creativecommons.org/licenses/by-nc-sa/4.0\n",
    "\n",
    "\n",
    "# Learning outcomes\n",
    "\n",
    "- Apply statistical and visualization methods to uncover sources of racial bias in a real-world algorithm.\n",
    "- Discuss and evaluate how algorithms are situated in real world contexts; how they are deemed accurate, relevant or fair, and by whom.\n",
    "- Discuss and evaluate how algorithms trained on past data respond (or fail to respond) to a dynamic world.\n",
    "\n",
    "# Lecture outline\n",
    "\n",
    "- What is health risk?\n",
    "  - Who needs a health risk score?\n",
    "  - Who uses health risk scores, and why?\n",
    "  - Example of use\n",
    "- **Discussion questions**:\n",
    "  - If you had to evaluate health risk, what sorts of data would you use?\n",
    "- Assumptions in health risk scores\n",
    "  - Predicting the future from past data\n",
    "  - A dynamic world (changes in race, health, urbanization).\n",
    "  - Epistemic risks (under-reporting of medical needs, unequal access to care).\n",
    "- **Discussion questions**:\n",
    "  - What would it mean for a healthcare score to be \"fair\" or \"unfair\"?\n",
    "  - What kinds of inputs might a \"fair\" algorithm have?\n",
    "  - What inputs might cause an algorithm to produce \"unfair\" outcomes?\n",
    "- The health risk index\n",
    "  - Cost as a proxy of health need\n",
    "  - Explain how proxy was evaluated for bias\n",
    "- **Discussion questions**\n",
    "  - How does the notion of risk score reflect on health as a concept? How does this score have us understand health as a concept, and/or the role of health care?\n",
    "- Design vs use.\n",
    "  - Who builds the health score?\n",
    "  - Who uses health scores?\n",
    "- **Discussion questions**\n",
    "  - Who gets to produce health scores? What is their perspective on the health score, and how might their perspective differ from those who use the health scores to make decisions? How might they differ from the perspectives of patients? Why do these differences in perspective matter?\n",
    "\n",
    "# Package Requirements\n",
    "\n",
    "- [Pandas](https://pandas.pydata.org) and [NumPy](https://numpy.org) for data exploration and manipulation\n",
    "- [Matplotlib](https://matplotlib.org)/[Seaborn](https://seaborn.pydata.org/index.html) for data visualization\n",
    "- [Statsmodels](https://www.statsmodels.org/stable/index.html) for creating and fitting statistical models\n",
    "\n",
    "# Lab\n",
    "\n",
    "This lab is based off of [Dissecting racial bias in an algorithm used to manage the health of populations](https://science.sciencemag.org/content/366/6464/447) by Ziad Obermeyer et al (2019).\n",
    "\n",
    "## Background\n",
    "\n",
    "To effectively manage patients, health systems often need to estimate particular\n",
    "patients' health risks. Using quantitative measures, or \"risk scores,\"\n",
    "healthcare providers can prioritize patients and allocate resources to patients\n",
    "who need them most.\n",
    "\n",
    "In this lab, we examine an algorithm widely-used in industry to establish quantitative risk scores for patients. This algorithm uses *medical cost* (i.e., the amount a patient spends on medical care) as a proxy for risk. Through analysis of this data, we will discover how this algorithm embeds a bias against Black patients, undervaluing their medical risk relative to White patients. Crucially, this bias is not immediately visible when comparing medical costs across White and Black pateints.\n",
    "\n",
    "The key insight of Obermeyer et al's work is that bias frequently slips into algorithmic systems unnoticed, particularly when sensitive characteristics (such as race) are ommitted or backgrounded in the data science process. In this case, bias in algorithms affects people's lives very concretely: the bias in the algorithm described here would make it more difficult for Black patients to recieve the care they need.\n",
    "\n",
    "In this lab, we will learn how to uncover bias in algorithms, using the medical risk score example from Obermeyer et al's paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents \n",
    "\n",
    "1. [Medical Cost and Risk](#0)<br>\n",
    "2. [Chronic Illness and Risk](#1)<br>\n",
    "3. [Interactions Between Cost and Illness](#2)<br>\n",
    "4. [Conclusions and Takeaways](#3)<br>\n",
    "5. [Reflection Questions](#4)<br>\n",
    "6. [References](#5)<br>\n",
    "7. [Feedback](#6)<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "id": "B4AtgFvfIpjv",
    "outputId": "702842aa-d412-466d-eec5-b2240a779143"
   },
   "outputs": [],
   "source": [
    "# import statements\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.ticker\n",
    "from statsmodels.nonparametric.smoothers_lowess import lowess\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9BN6QhFqMKYn"
   },
   "outputs": [],
   "source": [
    "#utility function\n",
    "def convert_to_percentile(df, col_name):\n",
    "    \"\"\"Convert column to percentile.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Data dataframe.\n",
    "    col_name : str\n",
    "        Name of column in df to convert to percentile.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.Series\n",
    "        Column converted to percentile from 1 to 100\n",
    "\n",
    "    \"\"\"\n",
    "    return pd.qcut(df[col_name].rank(method='first'), 100,\n",
    "                   labels=range(1, 101))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wY-sa4O5IqCJ"
   },
   "source": [
    "## 1. Medical Cost and Risk <a id='0'></a>\n",
    "\n",
    "To help hospitals and insurance companies identify patients who should qualify for “high-risk care management” programs, the algorithm assigns each patient a risk score. It predicts a patient’s total medical expenditure based on data from insurance claims (age, sex, diagnosis codes, etc.) and uses this variable as a proxy for health care needs.  Patient risk scores are then generated as functions of their predicted expenditures.\n",
    "\n",
    "If the model is calibrated across race in terms of risk score and expenditure, Black and White patients with a given risk score should have similar total medical expenditures, on average.\n",
    "\n",
    "To see if this is true, we will generate a graph that shows the mean total medical expenditure by race given a risk score percentile.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 190
    },
    "id": "GAPNyZWblYpI",
    "outputId": "db4c7e3f-ed02-4744-9320-7950ff949cba"
   },
   "outputs": [],
   "source": [
    "#first, let's load the data we will need\n",
    "data = pd.read_csv('health-care-bias-lab.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "id": "qRr4YHhrJs0X",
    "outputId": "a8f2305f-19a3-4e09-a8a8-cd3e3f335756"
   },
   "outputs": [],
   "source": [
    "#add a column of risk percentiles to the dataframe called 'risk_percentile'\n",
    "risk_percentile = convert_to_percentile(data, \"risk_score_t\")\n",
    "data[\"risk_percentile\"] = risk_percentile\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "id": "r6PlT59kLq_F",
    "outputId": "ed746f98-c6ea-4f7a-b893-a90fd3e80dcd"
   },
   "outputs": [],
   "source": [
    "#create dataframe with the average total medical expenditure for each race at each risk percentile\n",
    "group_cost = data.groupby([\"risk_percentile\", \"race\"])[[\"cost_t\"]].mean().reset_index()\n",
    "group_cost.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K2FmeKvoLKMT"
   },
   "outputs": [],
   "source": [
    "#divide group_cost into two dataframes based on race\n",
    "b_cost = group_cost[group_cost['race'] == 'black']\n",
    "w_cost = group_cost[group_cost['race'] == 'white']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "id": "DE_PxzyEpxIQ",
    "outputId": "b6d8c47e-08b3-42ba-989a-b764026645b5"
   },
   "outputs": [],
   "source": [
    "#scatterplot of risk percentile against cost, splitting on race\n",
    "ax = sns.scatterplot(x = \"risk_percentile\", y = \"cost_t\", data = group_cost, hue = \"race\", marker = \"x\", legend = \"full\")\n",
    "plt.yscale('log')\n",
    "ax.set_yticks([1000, 3000, 8000, 20000, 60000])\n",
    "ax.get_yaxis().set_major_formatter(matplotlib.ticker.ScalarFormatter())\n",
    "plt.legend;\n",
    "sns.set(rc={'figure.figsize':(9,7)})\n",
    "plt.xlabel('Risk Percentile', size = 17)\n",
    "plt.ylabel('Total Medical Expenditure', size = 17);\n",
    "#plt.title();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hqoKswf-JV7K"
   },
   "outputs": [],
   "source": [
    "#fit a LOWESS (Locally Weighted Scatterplot Smoothing) model to the scatterplot above for each race\n",
    "risk_percentile_array_b = np.array(b_cost['risk_percentile'])\n",
    "risk_percentile_array_w = np.array(w_cost['risk_percentile'])\n",
    "b_cost_array = np.array(b_cost['cost_t'])\n",
    "w_cost_array = np.array(w_cost['cost_t'])\n",
    "b_cost_lowess = lowess(b_cost_array, risk_percentile_array_b, it=35, frac=0.2, delta=2)\n",
    "w_cost_lowess = lowess(w_cost_array, risk_percentile_array_w, it=35, frac=0.2, delta=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "id": "GRoFxtbYyHI7",
    "outputId": "df576c50-3b92-4fd9-be74-cf13307cbc61"
   },
   "outputs": [],
   "source": [
    "#plot the model on the scatterplot\n",
    "ax = sns.scatterplot(x = \"risk_percentile\", y = \"cost_t\", data = group_cost, hue = \"race\", marker = \"x\", legend = \"full\")\n",
    "plt.yscale('log')\n",
    "plt.plot(risk_percentile_array_b, b_cost_lowess[:, 1])\n",
    "plt.plot(risk_percentile_array_w, w_cost_lowess[:, 1])\n",
    "ax.set_yticks([1000, 3000, 8000, 20000, 60000])\n",
    "ax.get_yaxis().set_major_formatter(matplotlib.ticker.ScalarFormatter())\n",
    "plt.xlabel('Risk Percentile', size = 17)\n",
    "plt.ylabel('Total Medical Expenditure', size = 17);\n",
    "#plt.title();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3EHyhQ6HJXbf"
   },
   "source": [
    "What do you notice about the relationship between medical expenditure and risk score by race?\n",
    "\n",
    "Can you conclude from this data that the model is fair or not fair?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iaBPTO9OJstu"
   },
   "source": [
    "**Example answer**: *A Black patient with a particular risk score appears to spend about the same amount on medical expenses than a white patient with the same risk score. If we assume that cost is a proxy for medical need, this model may be fair. However, we cannot assume that this assumption holds. For example, Black and White patients may have unequal access to care for financial, insurance or other structural reasons, which would make this risk score undervalue the true medical risk of Black patients.* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "19CQRP0cJvU5"
   },
   "source": [
    "## 2. Chronic Illness and Risk <a id='1'></a>\n",
    "\n",
    "Next, we will check to see if the model is calibrated across groups in terms of risk score and chronic illness. Equivalently, for a given risk score do Black and White patients have the same level of health? \n",
    "\n",
    "If cost is a good proxy for need, we would expect this graph to be as balanced as the prior graph.  In other words, health care cost should not vary conditional on health between groups.\n",
    "\n",
    "Generate a graph that shows the mean number of chronic illnesses by race given a risk score percentile.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "id": "45SnmB-XLTEz",
    "outputId": "c8f7ce46-1214-484c-c4f4-1ab1da95e49a"
   },
   "outputs": [],
   "source": [
    "# create dataframe with the average number of chronic illnesses for each race at each risk percentile\n",
    "grouped_by_race = data.groupby([\"risk_percentile\", \"race\"])[[\"gagne_sum_t\"]].mean().reset_index()\n",
    "grouped_by_race.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kbYEyXWELZfA"
   },
   "outputs": [],
   "source": [
    "# divide the grouped dataframe into two dataframes based on race\n",
    "black_patients = grouped_by_race[grouped_by_race['race'] == 'black']\n",
    "white_patients = grouped_by_race[grouped_by_race['race'] == 'white']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "W62DjFtgsGCM",
    "outputId": "aea8d426-820d-4e91-841f-7b653a470222"
   },
   "outputs": [],
   "source": [
    "# create a scatterplot of risk percentile against average number of chronic ilnesses, splitting on race\n",
    "ax = sns.scatterplot(x=\"risk_percentile\", y=\"gagne_sum_t\", data=grouped_by_race, hue=\"race\", marker=\"x\", legend=\"full\");\n",
    "plt.xlabel('Risk Percentile', size = 17)\n",
    "plt.ylabel('Average Number of Chronic Illnesses', size = 17);\n",
    "#plt.title();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "id": "CKC07jBILlSN",
    "outputId": "0d28e75e-fba1-45c6-a6ce-cf73b6f1d89a"
   },
   "outputs": [],
   "source": [
    "#fit a Generalized Linear Model (GLM) to the scatterplot above for each race\n",
    "X_b = sm.add_constant(np.array(black_patients[\"risk_percentile\"]))\n",
    "model_b = sm.GLM(black_patients[\"gagne_sum_t\"], X_b, family=sm.families.Gaussian(link=sm.families.links.log))\n",
    "model_b_results = model_b.fit()\n",
    "\n",
    "X_w = sm.add_constant(np.array(white_patients[\"risk_percentile\"]))\n",
    "model_w = sm.GLM(white_patients[\"gagne_sum_t\"], X_w, family=sm.families.Gaussian(link=sm.families.links.log))\n",
    "model_w_results = model_w.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "id": "_3hWBonhJuTr",
    "outputId": "cf661bef-6a7a-49fd-d987-a88132ca2571"
   },
   "outputs": [],
   "source": [
    "# plot the model on the scatterplot\n",
    "sns.scatterplot(x=\"risk_percentile\", y=\"gagne_sum_t\", data=grouped_by_race, hue=\"race\", marker=\"x\", legend=\"full\")\n",
    "plt.plot(black_patients[\"risk_percentile\"], model_b_results.predict())\n",
    "plt.plot(white_patients[\"risk_percentile\"], model_w_results.predict())\n",
    "plt.legend();\n",
    "plt.xlabel('Risk Percentile', size = 17)\n",
    "plt.ylabel('Average Number of Chronic Illnesses', size = 17);\n",
    "#plt.title();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qIEeHKYUKb-j"
   },
   "source": [
    "What do you notice about the relationship between chronic illness and risk score by race?\n",
    "\n",
    "Can you conclude from this data that the model is fair or not fair?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8sT9aklCKnRi"
   },
   "source": [
    "**Example answer**: *There is a difference in the number of chronic illnesses by race. Since a Black patient tends to have more markers of chronic illness than a White patient with the same risk score, this model does not appear to be fair.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kZhqmFQOKuxi"
   },
   "source": [
    "## 3. Interactions Between Cost and Illness <a id='2'></a>\n",
    "\n",
    "Our work above shows us that a Black patient and a White patient with the same risk score tend to spend the same amount on medical care on average, yet the Black patient tends to have more chronic illnesses.\n",
    "\n",
    "To understand this interaction, generate a graph that shows the mean total medical expenditure by race, given the number of chronic illnesses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "id": "OootdJVKLyCx",
    "outputId": "51358d52-c0e9-40c0-fe18-3d1b882472aa"
   },
   "outputs": [],
   "source": [
    "#add a column of illness percentiles to the dataframe called 'illness_percentile'\n",
    "illness_percentile = convert_to_percentile(data, \"gagne_sum_t\")\n",
    "data['illness_percentile'] = illness_percentile\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "id": "RYBDYKD_uaSq",
    "outputId": "712eb75c-4dbf-49b8-88f8-8a29d9769582"
   },
   "outputs": [],
   "source": [
    "#create dataframe with the average total medical expenditure for each race at each illness percentile\n",
    "illnesses = data.groupby([\"illness_percentile\", \"race\"])[[\"cost_t\"]].mean().reset_index()\n",
    "illnesses.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "arGPABGoL1hV"
   },
   "outputs": [],
   "source": [
    "#divide illnesses into two dataframes based on race\n",
    "illness_b = illnesses[illnesses['race'] == 'black']\n",
    "illness_w = illnesses[illnesses['race'] == 'white']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "id": "bWpf6htIvg0c",
    "outputId": "c6c34792-1173-4bf0-ee1f-013869c55f4f"
   },
   "outputs": [],
   "source": [
    "#scatterplot of illness percentile against cost, splitting on race\n",
    "ax = sns.scatterplot(x = \"illness_percentile\", y = \"cost_t\", data = illnesses, hue = \"race\", marker = \"x\", legend = \"full\")\n",
    "plt.yscale('log')\n",
    "ax.set_yticks([1000, 3000, 8000, 20000, 60000])\n",
    "ax.get_yaxis().set_major_formatter(matplotlib.ticker.ScalarFormatter())\n",
    "plt.xlabel('Illness Percentile', size = 17)\n",
    "plt.ylabel('Total Medical Expenditures', size = 17);\n",
    "#plt.title();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0GE1_aZaMxy_"
   },
   "outputs": [],
   "source": [
    "#fit a LOWESS (Locally Weighted Scatterplot Smoothing) model to the scatterplot above for each race\n",
    "illness_percentile_array_b = np.array(illness_b['illness_percentile'])\n",
    "illness_percentile_array_w = np.array(illness_w['illness_percentile'])\n",
    "illness_cost_b = np.array(illness_b['cost_t'])\n",
    "illness_cost_w = np.array(illness_w['cost_t'])\n",
    "b_illness_lowess = lowess(illness_cost_b, illness_percentile_array_b, it=35, frac=0.3, delta=2)\n",
    "w_illness_lowess = lowess(illness_cost_w, illness_percentile_array_w, it=35, frac=0.3, delta=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "id": "v_lLZlMvybtB",
    "outputId": "29089084-83ab-48b4-edfa-d8945dca9e38"
   },
   "outputs": [],
   "source": [
    "#plot the model on the scatterplot\n",
    "ax = sns.scatterplot(x = \"illness_percentile\", y = \"cost_t\", data = illnesses, hue = \"race\", marker = \"x\", legend = \"full\")\n",
    "plt.yscale('log')\n",
    "plt.plot(illness_percentile_array_b, b_illness_lowess[:, 1])\n",
    "plt.plot(illness_percentile_array_w, w_illness_lowess[:, 1])\n",
    "ax.set_yticks([1000, 3000, 8000, 20000, 60000])\n",
    "ax.get_yaxis().set_major_formatter(matplotlib.ticker.ScalarFormatter())\n",
    "plt.xlabel('Illness Percentile', size = 17)\n",
    "plt.ylabel('Total Medical Expenditure', size = 17);\n",
    "#plt.title();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TWVBYMvMNRei"
   },
   "source": [
    "What can you conclude about the relationship between cost and chronic illness? Why might this relationship exist? What are consequences for the risk score model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ugDwyPfJNeWQ"
   },
   "source": [
    "**Example answer**:\n",
    "\n",
    "*Given a Black patient and a White patient with the same number of chronic illnesses, the Black patient tends to spend less. This relationship may exist due to unequal access to medical care, perhaps due to limited financial resources among Black patients, worse access to medical facilities, and/or unequal access to employment-related medical benefits such as health insurance. Another factor might be bias in the medical system itself (e.g., doctors and nurses paying less attention to Black patients compared to White patients).*\n",
    "\n",
    "*For our model, this relationship demonstrates a racial bias in the relationship between cost and chronic illness. In effect, it means the risk score model will systematically undervalue the medical risk of Black patients.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "esq4RAPfOnro"
   },
   "source": [
    "## 4. Conclusions and Takeaways <a id='3'></a>\n",
    "\n",
    "Even systems that appear balanced across racial groups at first glance may belie underlying biases in the datasets. Thus, seemingly unbiased predictors can in fact be highly correlated with a biasing variable such as race, gender, income or other relational characteristics.\n",
    "\n",
    "In this example, bias emerged from using an indicator of need (cost) that was itself influenced by race. Biased estimation of need between races resulted.\n",
    "\n",
    "To better understand the ways in which race influences health care cost, here is a segment from Obermeyer et al’s paper:\n",
    " \n",
    ">The literature broadly suggests two main potential channels. **First, poor patients face substantial barriers to accessing health care, even when enrolled in insurance plans.** Although the population we study is entirely insured, there are many other mechanisms by which poverty can lead to disparities in use of health care: geography and differential access to transportation, competing demands from jobs or child care, or knowledge of reasons to seek care (1-3). To the extent that race and socioeconomic status are correlated, these factors will differentially affect Black patients. **Second, race could affect costs directly via several channels: direct (“taste-based”) discrimination, changes to the doctor–patient relationship, or others.** A recent trial randomly assigned Black patients to a Black or White primary care provider and found significantly higher uptake of recommended preventive care when the provider was Black (4). This is perhaps the most rigorous demonstration of this effect, and it fits with a larger literature on potential mechanisms by which race can affect health care directly. For example, it has long been documented that Black patients have reduced trust in the health care system (5), a fact that some studies trace to the revelations of the Tuskegee study and other adverse experiences (6). A substantial literature in psychology has documented physicians’ differential perceptions of Black patients, in terms of intelligence, affiliation (7), or pain tolerance (8). **Thus, whether it is communication, trust, or bias, something about the interactions of Black patients with the health care system itself leads to reduced use of health care. The collective effect of these many channels is to lower health spending substantially for Black patients, conditional on need—a finding that has been appreciated for at least two decades (9).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZckgMXS24TYX"
   },
   "source": [
    "## 5. Reflection Questions <a id='4'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VeHiQ6fz3nuC"
   },
   "source": [
    "Here are two final open-ended questions for you to answer.\n",
    "\n",
    "1. How could we use the data we have to create new proxies for health needs that may be less biased than medical costs?\n",
    "\n",
    "**Example answer**: *The authors of the paper created an index variable that combined health prediction with cost prediction which  resulted in an 84% reduction in bias.*\n",
    "\n",
    "2. What are other applications of prediction algorithms where this type of bias may also arise?\n",
    "\n",
    "**Example Answer**: *Recidivism prediction algorithms, credit score algorithms, etc.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bpnQ5tGH4A-9"
   },
   "source": [
    "## 6. References <a id='5'></a>\n",
    "\n",
    "1. K. Fiscella, P. Franks, M. R. Gold, C. M. Clancy, JAMA 283, 2579–2584 (2000).\n",
    "2. N. E. Adler, K. Newman, Health Aff. 21, 60–76 (2002).\n",
    "3. N. E. Adler, W. T. Boyce, M. A. Chesney, S. Folkman, S. L. Syme, JAMA 269, 3140–3145 (1993).\n",
    "4. M. Alsan, O. Garrick, G. C. Graziani, “Does diversity matter for health? Experimental evidence from Oakland” (National Bureau of Economic Research, 2018).\n",
    "5. K. Armstrong, K. L. Ravenell, S. McMurphy, M. Putt, Am. J. Public Health 97, 1283–1289 (2007).\n",
    "6. M. Alsan, M. Wanamaker, Q. J. Econ. 133, 407–455 (2018).\n",
    "7. M. van Ryn, J. Burke, Soc. Sci. Med. 50, 813–828 (2000).\n",
    "8. K. M. Hoffman, S. Trawalter, J. R. Axt, M. N. Oliver, Proc. Natl. Acad. Sci. U.S.A. 113, 4296–4301 (2016).\n",
    "9. J. J. Escarce, F. W. Puffer, in Racial and Ethnic Differences in the Health of Older Americans (National Academies Press, 1997), chap. 6; www.ncbi.nlm.nih.gov/books/ NBK109841/.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Feedback <a id='6'></a>\n",
    "\n",
    "**Instructors**: Please [provide feedback](https://docs.google.com/forms/d/1UuUVBBMTU_2aMvzsGnTR_4i1w3F6tLaaqdIr7dQrgSI/edit?ts=5efa771b&dods) to help improve this lab.\n",
    "\n",
    "**Students**: Please [provide feedback](https://docs.google.com/forms/d/1jI8oXRkqD1l1ARuZR1y9W_qkOystPr-YEyywNDez46M/edit?ts=5efa772a&dods) to help improve this lab."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Health_care_lab_for_review-text.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
